# Continuous Improvement Framework for EduScan AI System

**Last updated:** 2025-08-08  
**Responsible Officer:** Maria-Antònia Guardiola, AI Governance Officer  
**System Covered:** EduScan - AI Tool for Formative Writing Feedback



## 1. Purpose

This framework outlines the continuous improvement process for the EduScan AI system. It ensures that insights from monitoring, audits, and user feedback are systematically used to enhance system performance, fairness and compliance over time.



## 2. Framework Cycle: Plan → Do → Check → Act (PDCA)

### ▶️ Plan
- Define system goals: Improve quality and fairness of formative feedback.
- Set baseline KPIs:
  - Accuracy benchmark: ≥ 90% teacher-AI comment alignment.
  - Bias tolerance: < 5% variance in accuracy across student demographics.
  - Teacher satisfaction: > 80% satisfaction with AI support.

### ▶️ Do
- System in use across grades 5–8 in English Language Arts classes.
- Teachers review all AI outputs before sharing with students.
- Monitoring dashboard and incident reporting forms active.

### ▶️ Check
- Monthly review of performance dashboard by AI Governance Officer.
- Quarterly internal audits, including bias, fairness and compliance checks.
- Feedback from teachers and students collected every term via survey.

### ▶️ Act
- Document identified issues in the improvement log (see below).
- Trigger specific actions (e.g., retrain, update policy, user training).
- Reassess after implementation of any major change.


## 3. Review Structures

- **AI Governance Committee:** Meets quarterly to review EduScan’s performance.
  - Members: AI Governance Officer, IT rep, two ELA teachers, data protection lead.
- **Annual Review:** Summarized audit findings and key improvement actions reported to school leadership.
- **Re-training triggers:** Major curriculum changes, demographic shifts, or new model updates from vendor.



## 4. Feedback Mechanisms

- **Teachers:** Internal feedback form embedded in EduScan dashboard.
- **Students:** Post-assignment feedback survey (shortform, optional).
- **Parents:** Annual AI governance report shared with opportunity to comment.



## 5. Improvement Log Template

| Issue ID | Date Found | Description | Severity | Assigned To | Resolution | Date Resolved |
|----------|------------|-------------|----------|--------------|------------|----------------|
| 001 | 2025-08-01 | Lower accuracy for non-native speakers | Medium | Vendor Support | Retrained model requested | TBD |
| 002 | 2025-08-05 | Feedback phrasing confusion among Year 6 students | Low | Curriculum Lead | Simplified language guide issued | 2025-08-10 |



## 6. KPIs and Thresholds

| KPI | Target | Alert Threshold | Action |
|-----|--------|------------------|--------|
| Accuracy (AI vs. Teacher) | ≥ 90% | < 85% | Review model performance |
| Satisfaction (Teachers) | ≥ 80% | < 70% | Trigger staff workshop |
| Satisfaction (Students) | ≥ 70% | < 60% | Qualitative review |
| Fairness Gap (across groups) | ≤ 5% | > 7% | Bias analysis |
| Incidents per term | < 2 | ≥ 2 | Trigger audit |



## 7. Integration with School Improvement Planning

This framework is integrated into the school’s annual improvement plan. AI tools such as EduScan are reviewed as part of instructional quality and equity strategies. Metrics and major actions are presented during the end-of-year governance review.



## 8. Version Control

- Initial version: 2025-08-08
- Reviewed: [TBD – next quarter]
- Next full review scheduled: 2026-01-15



*This document fulfills post-deployment improvement obligations under EU AI Act Articles 17 and 20, and supports GDPR accountability principles.*
